{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input_data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('xAttack',axis=1)\n",
    "y = df['xAttack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "X = (X-np.mean(X,axis=0))/(np.std(X,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintestvalidatesplit(data):\n",
    "    x,y = data[0], data[1]\n",
    "    n = x.shape[0]\n",
    "    k = int(n*0.8)\n",
    "    x_train = x[:k]\n",
    "    y_train = y[:k]\n",
    "    x_val = x[k:]\n",
    "    y_val = y[k:]\n",
    "    return [x_train,y_train],[x_val,y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_derivative(x):\n",
    "    return np.where(x > 0, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.where(x > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (2/(1+np.exp(-2*x))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_derivative(x):\n",
    "    return 1 - (x * x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self,layerSizes,activation,learningrate = 0.01):\n",
    "        self.shape = layerSizes\n",
    "        self.activation = activation\n",
    "        self.learningrate = learningrate\n",
    "        self.activations = {'sigmoid':[sigmoid,sigmoid_derivative],\n",
    "                           'relu':[relu,relu_derivative],\n",
    "                           'tanh':[tanh,tanh_derivative],\n",
    "                           'linear':[linear,linear_derivative]}\n",
    "        n = len(layerSizes)\n",
    "        self.layers = []\n",
    "        self.layers.append(np.ones(self.shape[0]))\n",
    "        for i in range(1,n):\n",
    "            self.layers.append(np.ones(self.shape[i]))\n",
    "        self.weights = []\n",
    "        for i in range(n-1):\n",
    "            temp = np.zeros((self.layers[i].size,self.layers[i+1].size), dtype = 'd')\n",
    "            self.weights.append(np.random.randn(*temp.shape))\n",
    "        self.derivative = [0,]*len(self.weights)\n",
    "\n",
    "    def forwardpass(self,data):\n",
    "        self.layers[0] = data\n",
    "        for i in range(1,len(self.shape)):\n",
    "            self.layers[i][...] = self.activations[self.activation][0](np.dot(self.layers[i-1],self.weights[i-1]))\n",
    "        return self.layers[-1]\n",
    "\n",
    "\n",
    "    def backpropogation(self, target, momentum=0.1):\n",
    "        error = target - self.layers[-1]\n",
    "        weight_deltas = []\n",
    "        weight_delta = error*self.activations[self.activation][1](self.layers[-1])\n",
    "        weight_deltas.append(weight_delta)\n",
    "\n",
    "        for i in range(len(self.shape)-2,0,-1):\n",
    "            weight_delta = np.dot(weight_deltas[0],self.weights[i].T)*self.activations[self.activation][1](self.layers[i])\n",
    "            weight_deltas.insert(0,weight_delta)\n",
    "            \n",
    "        for i in range(len(self.weights)):\n",
    "            layer = np.atleast_2d(self.layers[i])\n",
    "            weight_delta = np.atleast_2d(weight_deltas[i])\n",
    "            der = np.dot(layer.T,weight_delta)\n",
    "            self.weights[i] += self.learningrate*der + momentum*self.derivative[i]\n",
    "            self.derivative[i] = der\n",
    "\n",
    "        return (error**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMLP(network,samples, epochs=10, momentum=0.1):\n",
    "    error_set = []\n",
    "    for i in range(epochs):\n",
    "        print('Epoch: ', i+1)\n",
    "        n = samples[0].shape[0]\n",
    "        error = 0\n",
    "        for j in range(n):\n",
    "            out = network.forwardpass(samples[0][j] )\n",
    "            error += network.backpropogation( samples[1][j], momentum )\n",
    "        error_set.append(error/n)\n",
    "        print('Training error',error/n)\n",
    "    return error_set, error/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error 0.7786268105938058\n",
      "Epoch:  2\n",
      "Training error 0.7960363673271034\n",
      "Epoch:  3\n",
      "Training error 0.7995105627133938\n",
      "Epoch:  4\n",
      "Training error 0.8062014209028044\n",
      "Epoch:  5\n",
      "Training error 0.7965804093261678\n",
      "Epoch:  6\n",
      "Training error 0.8156787089778409\n",
      "Epoch:  7\n",
      "Training error 0.812937904196821\n",
      "Epoch:  8\n",
      "Training error 0.7709936085284226\n",
      "Epoch:  9\n",
      "Training error 0.7694184370997309\n",
      "Epoch:  10\n",
      "Training error 0.756600764097854\n",
      "Epoch:  11\n",
      "Training error 0.7658273358453733\n",
      "Epoch:  12\n",
      "Training error 0.7648781643118375\n",
      "Epoch:  13\n",
      "Training error 0.7483377355644321\n",
      "Epoch:  14\n",
      "Training error 0.7336940360142689\n",
      "Epoch:  15\n",
      "Training error 0.7289486116477437\n",
      "Epoch:  16\n",
      "Training error 0.7279297721779345\n",
      "Epoch:  17\n",
      "Training error 0.7237578798080379\n",
      "Epoch:  18\n",
      "Training error 0.7267322518084447\n",
      "Epoch:  19\n",
      "Training error 0.7234479745177119\n",
      "Epoch:  20\n",
      "Training error 0.7167966136763305\n",
      "Epoch:  21\n",
      "Training error 0.7417335308252123\n",
      "Epoch:  22\n",
      "Training error 0.740562369861287\n",
      "Epoch:  23\n",
      "Training error 0.728905164179125\n",
      "Epoch:  24\n",
      "Training error 0.7226564365788612\n",
      "Epoch:  25\n",
      "Training error 0.7264583341594919\n",
      "Epoch:  26\n",
      "Training error 0.7224864025663168\n",
      "Epoch:  27\n",
      "Training error 0.7164117162611383\n",
      "Epoch:  28\n",
      "Training error 0.7327810943053233\n",
      "Epoch:  29\n",
      "Training error 0.7344864601414763\n",
      "Epoch:  30\n",
      "Training error 0.7343547059287228\n",
      "Epoch:  31\n",
      "Training error 0.7390306047026023\n",
      "Epoch:  32\n",
      "Training error 0.7495152968763636\n",
      "Epoch:  33\n",
      "Training error 0.7697626238919592\n",
      "Epoch:  34\n",
      "Training error 0.7508519533771985\n",
      "Epoch:  35\n",
      "Training error 0.7413733205034071\n",
      "Epoch:  36\n",
      "Training error 0.7200340387767846\n",
      "Epoch:  37\n",
      "Training error 0.7233930372257911\n",
      "Epoch:  38\n",
      "Training error 0.7451414573888132\n",
      "Epoch:  39\n",
      "Training error 0.7553479325108688\n",
      "Epoch:  40\n",
      "Training error 0.754061117979789\n",
      "Epoch:  41\n",
      "Training error 0.7464965898818665\n",
      "Epoch:  42\n",
      "Training error 0.7368486922733806\n",
      "Epoch:  43\n",
      "Training error 0.7276007194137529\n",
      "Epoch:  44\n",
      "Training error 0.7279650795594845\n",
      "Epoch:  45\n",
      "Training error 0.7249779759481431\n",
      "Epoch:  46\n",
      "Training error 0.7506970358036732\n",
      "Epoch:  47\n",
      "Training error 0.7316520547724398\n",
      "Epoch:  48\n",
      "Training error 0.71282041719998\n",
      "Epoch:  49\n",
      "Training error 0.7149177553062463\n",
      "Epoch:  50\n",
      "Training error 0.7144270120378612\n",
      "Epoch:  51\n",
      "Training error 0.7150299819563447\n",
      "Epoch:  52\n",
      "Training error 0.7155654996649087\n",
      "Epoch:  53\n",
      "Training error 0.7153795280520595\n",
      "Epoch:  54\n",
      "Training error 0.7228743394939358\n",
      "Epoch:  55\n",
      "Training error 0.7206210508350112\n",
      "Epoch:  56\n",
      "Training error 0.7220595742338808\n",
      "Epoch:  57\n",
      "Training error 0.7313663961346869\n",
      "Epoch:  58\n",
      "Training error 0.7053942899279115\n",
      "Epoch:  59\n",
      "Training error 0.7013850757875718\n",
      "Epoch:  60\n",
      "Training error 0.7023577131886226\n",
      "Epoch:  61\n",
      "Training error 0.6908504197582536\n",
      "Epoch:  62\n",
      "Training error 0.6935088561152555\n",
      "Epoch:  63\n",
      "Training error 0.6923588039389673\n",
      "Epoch:  64\n",
      "Training error 0.691668440025412\n",
      "Epoch:  65\n",
      "Training error 0.6877978770925662\n",
      "Epoch:  66\n",
      "Training error 0.6884578375164031\n",
      "Epoch:  67\n",
      "Training error 0.6869487061751886\n",
      "Epoch:  68\n",
      "Training error 0.6918778045565392\n",
      "Epoch:  69\n",
      "Training error 0.7089647080539665\n",
      "Epoch:  70\n",
      "Training error 0.7068172736746628\n",
      "Epoch:  71\n",
      "Training error 0.7092321037027145\n",
      "Epoch:  72\n",
      "Training error 0.7115739213785472\n",
      "Epoch:  73\n",
      "Training error 0.7108046808420772\n",
      "Epoch:  74\n",
      "Training error 0.7149765960164902\n",
      "Epoch:  75\n",
      "Training error 0.7316916267810273\n",
      "Epoch:  76\n",
      "Training error 0.7094619672686885\n",
      "Epoch:  77\n",
      "Training error 0.6882811158830694\n",
      "Epoch:  78\n",
      "Training error 0.6878565979171024\n",
      "Epoch:  79\n",
      "Training error 0.6919667492486711\n",
      "Epoch:  80\n",
      "Training error 0.7015923527623233\n",
      "Epoch:  81\n",
      "Training error 0.6904577911154413\n",
      "Epoch:  82\n",
      "Training error 0.6906906236077227\n",
      "Epoch:  83\n",
      "Training error 0.6949199071407999\n",
      "Epoch:  84\n",
      "Training error 0.68872725405233\n",
      "Epoch:  85\n",
      "Training error 0.6880215585643166\n",
      "Epoch:  86\n",
      "Training error 0.6960848877050176\n",
      "Epoch:  87\n",
      "Training error 0.6843388258352745\n",
      "Epoch:  88\n",
      "Training error 0.6836439441331936\n",
      "Epoch:  89\n",
      "Training error 0.6824835963271414\n",
      "Epoch:  90\n",
      "Training error 0.6829328776498532\n",
      "Epoch:  91\n",
      "Training error 0.6848610227922709\n",
      "Epoch:  92\n",
      "Training error 0.6816338786390882\n",
      "Epoch:  93\n",
      "Training error 0.681697151576785\n",
      "Epoch:  94\n",
      "Training error 0.6821994678064638\n",
      "Epoch:  95\n",
      "Training error 0.6847018642321442\n",
      "Epoch:  96\n",
      "Training error 0.6828667185044555\n",
      "Epoch:  97\n",
      "Training error 0.6814607430172877\n",
      "Epoch:  98\n",
      "Training error 0.6827526877568941\n",
      "Epoch:  99\n",
      "Training error 0.6824459799831852\n",
      "Epoch:  100\n",
      "Training error 0.6830302764271385\n"
     ]
    }
   ],
   "source": [
    "nn = NN([X.shape[1],14,X.shape[1]],'tanh',0.1)\n",
    "epochs = 100\n",
    "error_set, finalerror = trainMLP(nn,[X,X],epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = pd.DataFrame(np.dot(X,nn.weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_data.insert(loc=13, column='class', value=y)\n",
    "reduced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reduced_data).to_csv(\"../input_data/reducedData_b.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
