{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['id','age','yoe','income','zip','family','monthlyexp','education',\n",
    "           'mortagev','class','otherbankacc','certificate','internetbanking','creditcard']\n",
    "dataset = pd.read_csv(\"../input_data/LoanDataset/data.csv\", names=colnames, header=None)\n",
    "dataset = dataset.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>yoe</th>\n",
       "      <th>income</th>\n",
       "      <th>zip</th>\n",
       "      <th>family</th>\n",
       "      <th>monthlyexp</th>\n",
       "      <th>education</th>\n",
       "      <th>mortagev</th>\n",
       "      <th>class</th>\n",
       "      <th>otherbankacc</th>\n",
       "      <th>certificate</th>\n",
       "      <th>internetbanking</th>\n",
       "      <th>creditcard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2701</td>\n",
       "      <td>31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39</td>\n",
       "      <td>94590</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2716</td>\n",
       "      <td>42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>54</td>\n",
       "      <td>90089</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3359</td>\n",
       "      <td>59</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40</td>\n",
       "      <td>94536</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2492</td>\n",
       "      <td>38</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "      <td>92868</td>\n",
       "      <td>2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>937</td>\n",
       "      <td>62</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19</td>\n",
       "      <td>92109</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  age   yoe  income    zip  family  monthlyexp  education  mortagev  \\\n",
       "1  2701   31   5.0      39  94590       4         2.2        2.0         0   \n",
       "2  2716   42  18.0      54  90089       1         1.8        1.0         0   \n",
       "3  3359   59  35.0      40  94536       4         0.4        1.0         0   \n",
       "4  2492   38  14.0      80  92868       2         2.7        1.0         0   \n",
       "5   937   62  32.0      19  92109       1         1.5        3.0         0   \n",
       "\n",
       "   class  otherbankacc  certificate  internetbanking  creditcard  \n",
       "1    0.0           0.0          0.0              1.0         1.0  \n",
       "2    0.0           0.0          0.0              1.0         0.0  \n",
       "3    0.0           0.0          0.0              0.0         0.0  \n",
       "4    0.0           0.0          0.0              1.0         0.0  \n",
       "5    0.0           1.0          0.0              0.0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(dataset):\n",
    "    size = len(dataset)\n",
    "    tsize = int(size*0.6)\n",
    "    vsize = int(size*0.8)\n",
    "    training_data = dataset.iloc[:tsize].reset_index(drop=True)\n",
    "    validation_data = dataset.iloc[tsize:vsize].reset_index(drop=True)\n",
    "    testing_data = dataset.iloc[vsize:].reset_index(drop=True)\n",
    "    return training_data,validation_data,testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanstdv(col):\n",
    "    mean = col.mean()\n",
    "    stdv = col.std()\n",
    "    return mean,stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(x,mean,stdv):\n",
    "    exp = np.exp(-(np.power(x-mean,2)/(2*np.power(stdv,2))))\n",
    "    return (1/(np.sqrt(2*np.pi)*stdv))*exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classprobablities(column):\n",
    "    counts = column.value_counts()\n",
    "    prob = np.zeros(len(column.unique()))\n",
    "    for i in range(len(prob)):\n",
    "        prob[i] = counts.iloc[[i]].iloc[0]/column.size\n",
    "    return prob    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summaries(dataset):\n",
    "    summary = {}\n",
    "    attributes = dataset.keys()\n",
    "    for att in attributes:\n",
    "        summary[att] = []\n",
    "        summary[att].append([meanstdv(dataset[att])])\n",
    "#     print(summary)\n",
    "    return summary    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionalprobablities(dataset):\n",
    "    sets = []\n",
    "    classes = dataset['class'].unique()\n",
    "    for c in classes:\n",
    "        sets.append([(dataset.loc[dataset['class'] == c]).drop('class',axis=1)])\n",
    "    summary = []\n",
    "    for s in sets:\n",
    "        summary.append(summaries(s[0]))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(classprob,summary,classes,sample):\n",
    "    l = sample.size\n",
    "    pred = []\n",
    "    noc = len(classes)\n",
    "#     print(l,noc,classes[0])\n",
    "    attr = sample.keys()\n",
    "    for i in range(noc):\n",
    "        csummary = summary[i]\n",
    "        cprob = 1\n",
    "        for j in range(l):\n",
    "            tmean, tstdv = csummary[attr[j]][0][0][0],csummary[attr[j]][0][0][0]\n",
    "            cprob *= pdf(sample.iloc[j],tmean,tstdv)\n",
    "#             print(cprob)\n",
    "        pred.append(cprob*classprob[i])\n",
    "    pred = np.asarray(pred)\n",
    "    return classes[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpredictions(classprob,summary,classes,data):\n",
    "    predictions = []\n",
    "    l = len(data)\n",
    "    for i in range(l):\n",
    "        predictions.append(predict(classprob,summary,classes,data.iloc[i]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnnaivebayes(data):\n",
    "    from sklearn import metrics\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    model = GaussianNB()\n",
    "    X = data[0].drop('class',axis=1)\n",
    "    y = data[0]['class']\n",
    "    model.fit(X,y)\n",
    "    print(\"Stats on training data\")\n",
    "    predictions = model.predict(X)\n",
    "    stats(predictions,data[0]['class'])\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Stats on validation data\")\n",
    "    predictions = model.predict(data[1].drop('class',axis=1))\n",
    "    stats(predictions,data[1]['class'])\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Stats on testing data\")\n",
    "    predictions = model.predict(data[2].drop('class',axis=1))\n",
    "    stats(predictions,data[2]['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(preds,y): \n",
    "    TP,TN,FP,FN = 0,0,0,0\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == 0.0:\n",
    "            if y[i] == 0:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if y[i] == 0:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TP += 1\n",
    "    classification_error = safe_div((FP+FN),(TP+FP+TN+FN)) \n",
    "    accuracy = safe_div((TP+TN),(TP+FP+TN+FN)) \n",
    "    recall = safe_div(TP,(TP+FN))\n",
    "    precision = safe_div(TP,(TP+FP))\n",
    "    f1_score = safe_div(2,(safe_div(1,precision))+safe_div(1,recall))\n",
    "    #print(TP,TN,FP,FN)\n",
    "    print(\"Classification error:\",classification_error)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"Recall:\",recall)\n",
    "    print(\"Precision:\",precision)\n",
    "    print(\"F1 Score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on training data\n",
      "Classification error: 0.19340496480177843\n",
      "Accuracy: 0.8065950351982215\n",
      "Recall: 0.47876447876447875\n",
      "Precision: 0.24266144814090018\n",
      "F1 Score: 0.3220779220779221\n"
     ]
    }
   ],
   "source": [
    "training_data,validation_data,testing_data = train_validate_test_split(dataset)\n",
    "summary = conditionalprobablities(training_data)\n",
    "classprob = classprobablities(training_data['class'])\n",
    "print(\"Stats on training data\")\n",
    "predictions = getpredictions(classprob,summary,training_data['class'].unique(),training_data.drop('class',axis=1))\n",
    "stats(predictions,training_data['class'])\n",
    "\n",
    "# for i in range(5):\n",
    "#     print('i am i',i)\n",
    "#     print(predict(classprob,summary,dataset['class'].unique(),tdataset.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on validation data\n",
      "Classification error: 0.20444444444444446\n",
      "Accuracy: 0.7955555555555556\n",
      "Recall: 0.45263157894736844\n",
      "Precision: 0.24571428571428572\n",
      "F1 Score: 0.3185185185185185\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats on validation data\")\n",
    "predictions = getpredictions(classprob,summary,training_data['class'].unique(),validation_data.drop('class',axis=1))\n",
    "stats(predictions,validation_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on testing data\n",
      "Classification error: 0.21333333333333335\n",
      "Accuracy: 0.7866666666666666\n",
      "Recall: 0.3375\n",
      "Precision: 0.16265060240963855\n",
      "F1 Score: 0.21951219512195122\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats on testing data\")\n",
    "predictions = getpredictions(classprob,summary,training_data['class'].unique(),testing_data.drop('class',axis=1))\n",
    "stats(predictions,testing_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn library results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on training data\n",
      "Classification error: 0.11374583178955168\n",
      "Accuracy: 0.8862541682104483\n",
      "Recall: 0.5714285714285714\n",
      "Precision: 0.43023255813953487\n",
      "F1 Score: 0.49087893864013266\n",
      "\n",
      "\n",
      "\n",
      "Stats on validation data\n",
      "Classification error: 0.11444444444444445\n",
      "Accuracy: 0.8855555555555555\n",
      "Recall: 0.5263157894736842\n",
      "Precision: 0.46296296296296297\n",
      "F1 Score: 0.4926108374384236\n",
      "\n",
      "\n",
      "\n",
      "Stats on testing data\n",
      "Classification error: 0.10222222222222223\n",
      "Accuracy: 0.8977777777777778\n",
      "Recall: 0.55\n",
      "Precision: 0.44\n",
      "F1 Score: 0.4888888888888889\n"
     ]
    }
   ],
   "source": [
    "sklearnnaivebayes([training_data,validation_data,testing_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations:\n",
    "# The results produced by naive bayes is -80%, which is lower to the scikit learn results. The results can be \n",
    "# improved if the data is used with other classification algorithms or more data is available. \n",
    "# The new samples can also be add to the training data to make the model performance better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
