{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['class', 'a1', 'a2', 'a3','a4','a5','a6','id']\n",
    "dataset1 = pd.read_csv(\"../input_data/RobotDataset/Robot1\", names=colnames, header=None,delim_whitespace=True)\n",
    "dataset2 = pd.read_csv(\"../input_data/RobotDataset/Robot2\", names=colnames, header=None,delim_whitespace=True)\n",
    "frames = [dataset1,dataset2]\n",
    "dataset = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  a1  a2  a3  a4  a5  a6       id\n",
       "0      1   1   1   1   1   3   1   data_5\n",
       "1      1   1   1   1   1   3   2   data_6\n",
       "2      1   1   1   1   3   2   1  data_19\n",
       "3      1   1   1   1   3   3   2  data_22\n",
       "4      1   1   1   2   1   2   1  data_27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(v1,v2):\n",
    "    ary = spatial.distance.cdist(v1,v2, metric='minkowski')\n",
    "    return ary[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski(v1,v2):\n",
    "    ary = spatial.distance.cdist(v1,v2, metric='minkowski')\n",
    "    return ary[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(v1,v2):\n",
    "    ary = spatial.distance.cdist(v1,v2, metric='cosine')\n",
    "    return ary[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(dataset,sample,metric):\n",
    "    dist = []\n",
    "    l = len(dataset)\n",
    "    for i in range(l):\n",
    "        dist.append(metric(dataset.iloc[[i]],sample))\n",
    "    return np.asarray(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(dataset,sample,y,classes,k,metric):\n",
    "    dist = distances(dataset,sample,metric)\n",
    "    indices = dist.argsort()[:3]\n",
    "    counts = np.zeros(len(classes))\n",
    "    for i in indices:\n",
    "        counts[classes.index(y.iloc[i])] += 1\n",
    "    return classes[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(dataset):\n",
    "    size = len(dataset)\n",
    "    tsize = int(size*0.6)\n",
    "    vsize = int(size*0.8)\n",
    "    training_data = dataset.iloc[:tsize].reset_index(drop=True)\n",
    "    validation_data = dataset.iloc[tsize:vsize].reset_index(drop=True)\n",
    "    testing_data = dataset.iloc[vsize:].reset_index(drop=True)\n",
    "    return training_data,validation_data,testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_algorithm(training_data,test_data,classes,k,metric):\n",
    "    ttrain = training_data[['a1', 'a2', 'a3','a4','a5','a6']]\n",
    "    ttest = test_data[['a1', 'a2', 'a3','a4','a5','a6']]\n",
    "    y = training_data['class']\n",
    "    pred = []\n",
    "    for i in range(len(ttest)):\n",
    "        pred.append(knn(ttrain,ttest.iloc[[i]],y,classes,k,metric))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmatrix(preds,y,classes):\n",
    "    n = len(preds)\n",
    "    noc = len(classes)\n",
    "    matrix = np.zeros((noc,noc))\n",
    "    for i in range(n):\n",
    "        r = classes.index(preds[i])\n",
    "        c = classes.index(y[i])\n",
    "        matrix[r][c] += 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats2(confusionmatrix,classes): \n",
    "    n = len(classes)\n",
    "    precision = np.zeros(n)\n",
    "    recall = np.zeros(n)\n",
    "    f1 = np.zeros(n)\n",
    "    colsums = confusionmatrix.sum(axis=0)\n",
    "    rowsums = confusionmatrix.sum(axis=1)\n",
    "    dval = 0\n",
    "    for i in range(n):\n",
    "        precision[i] = confusionmatrix[i,i]/colsums[i]\n",
    "        recall[i] = confusionmatrix[i,i]/rowsums[i]\n",
    "        f1[i] = safe_div(2,(safe_div(1,precision[i]))+safe_div(1,recall[i]))\n",
    "        dval += confusionmatrix[i,i]\n",
    "    return dval/np.sum(confusionmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(confusionmatrix,classes): \n",
    "    n = len(classes)\n",
    "    precision = np.zeros(n)\n",
    "    recall = np.zeros(n)\n",
    "    f1 = np.zeros(n)\n",
    "    colsums = confusionmatrix.sum(axis=0)\n",
    "    rowsums = confusionmatrix.sum(axis=1)\n",
    "    dval = 0\n",
    "    for i in range(n):\n",
    "        precision[i] = confusionmatrix[i,i]/colsums[i]\n",
    "        recall[i] = confusionmatrix[i,i]/rowsums[i]\n",
    "        f1[i] = safe_div(2,(safe_div(1,precision[i]))+safe_div(1,recall[i]))\n",
    "        dval += confusionmatrix[i,i]\n",
    "    for i in range(n):\n",
    "        print(\"Recall of class\",classes[i],\":\",recall[i])\n",
    "        print(\"Precision of class\",classes[i],\":\",precision[i])\n",
    "        print(\"F1 Score of class\",classes[i],\":\",f1[i])\n",
    "        print('\\n')\n",
    "    print(\"Accuracy:\",dval/np.sum(confusionmatrix))\n",
    "    print(\"Classification error:\",1-(dval/np.sum(confusionmatrix)))\n",
    "    print(\"Overall Precision:\",np.mean(precision))\n",
    "    print(\"Overall Recall:\",np.average(recall))\n",
    "    print(\"Overall F1 Score:\",np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnstats(data):\n",
    "    datanames = ['training data','validation data','testing data']\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    X = data[0].drop('class',axis=1)\n",
    "    y = data[0]['class']\n",
    "    neigh.fit(X, y)\n",
    "    for i in range(len(data)):\n",
    "        print(\"Accuracy on:\",datanames[i])\n",
    "        preds = neigh.predict(data[i].drop('class',axis=1))\n",
    "        con_mat = confusion_matrix(data[i]['class'], preds)\n",
    "        stats(con_mat,data[i]['class'].unique())\n",
    "        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot Dataset Statistics\n"
     ]
    }
   ],
   "source": [
    "print(\"Robot Dataset Statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Stats\n",
      "Recall of class 1 : 0.8795180722891566\n",
      "Precision of class 1 : 0.9358974358974359\n",
      "F1 Score of class 1 : 0.9068322981366458\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.921875\n",
      "Precision of class 0 : 0.855072463768116\n",
      "F1 Score of class 0 : 0.8872180451127819\n",
      "\n",
      "\n",
      "Accuracy: 0.8979591836734694\n",
      "Classification error: 0.10204081632653061\n",
      "Overall Precision: 0.8954849498327759\n",
      "Overall Recall: 0.9006965361445782\n",
      "Overall F1 Score: 0.8970251716247138\n"
     ]
    }
   ],
   "source": [
    "training_data,validation_data,testing_data = train_validate_test_split(dataset.drop('id',axis=1))\n",
    "classes = list(training_data['class'].unique())\n",
    "preds = knn_algorithm(training_data,training_data,classes,3,euclidean)\n",
    "cm = confusionmatrix(preds,list(training_data['class']),list(training_data['class'].unique()))\n",
    "print(\"Training Data Stats\")\n",
    "stats(cm,training_data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Stats\n",
      "Recall of class 1 : 0.6956521739130435\n",
      "Precision of class 1 : 0.64\n",
      "F1 Score of class 1 : 0.6666666666666666\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.6538461538461539\n",
      "Precision of class 0 : 0.7083333333333334\n",
      "F1 Score of class 0 : 0.68\n",
      "\n",
      "\n",
      "Accuracy: 0.673469387755102\n",
      "Classification error: 0.326530612244898\n",
      "Overall Precision: 0.6741666666666667\n",
      "Overall Recall: 0.6747491638795986\n",
      "Overall F1 Score: 0.6733333333333333\n"
     ]
    }
   ],
   "source": [
    "preds = knn_algorithm(training_data,validation_data,classes,3,euclidean)\n",
    "cm = confusionmatrix(preds,list(validation_data['class']),list(training_data['class'].unique()))\n",
    "print(\"Validation Data Stats\")\n",
    "stats(cm,training_data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Stats\n",
      "Recall of class 1 : 0.3939393939393939\n",
      "Precision of class 1 : 0.6842105263157895\n",
      "F1 Score of class 1 : 0.5\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.6470588235294118\n",
      "Precision of class 0 : 0.3548387096774194\n",
      "F1 Score of class 0 : 0.45833333333333337\n",
      "\n",
      "\n",
      "Accuracy: 0.48\n",
      "Classification error: 0.52\n",
      "Overall Precision: 0.5195246179966044\n",
      "Overall Recall: 0.5204991087344029\n",
      "Overall F1 Score: 0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "preds = knn_algorithm(training_data,testing_data,classes,3,euclidean)\n",
    "cm = confusionmatrix(preds,list(testing_data['class']),list(training_data['class'].unique()))\n",
    "print(\"Testing Data Stats\")\n",
    "stats(cm,training_data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn library results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on: training data\n",
      "Recall of class 1 : 0.8840579710144928\n",
      "Precision of class 1 : 0.9384615384615385\n",
      "F1 Score of class 1 : 0.9104477611940298\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.9487179487179487\n",
      "Precision of class 0 : 0.9024390243902439\n",
      "F1 Score of class 0 : 0.9249999999999999\n",
      "\n",
      "\n",
      "Accuracy: 0.9183673469387755\n",
      "Classification error: 0.08163265306122447\n",
      "Overall Precision: 0.9204502814258912\n",
      "Overall Recall: 0.9163879598662208\n",
      "Overall F1 Score: 0.9177238805970149\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accuracy on: validation data\n",
      "Recall of class 1 : 0.8333333333333334\n",
      "Precision of class 1 : 0.6896551724137931\n",
      "F1 Score of class 1 : 0.7547169811320755\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.64\n",
      "Precision of class 0 : 0.8\n",
      "F1 Score of class 0 : 0.7111111111111111\n",
      "\n",
      "\n",
      "Accuracy: 0.7346938775510204\n",
      "Classification error: 0.26530612244897955\n",
      "Overall Precision: 0.7448275862068966\n",
      "Overall Recall: 0.7366666666666667\n",
      "Overall F1 Score: 0.7329140461215933\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accuracy on: testing data\n",
      "Recall of class 1 : 0.45161290322580644\n",
      "Precision of class 1 : 0.7368421052631579\n",
      "F1 Score of class 1 : 0.5599999999999999\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.7368421052631579\n",
      "Precision of class 0 : 0.45161290322580644\n",
      "F1 Score of class 0 : 0.5599999999999999\n",
      "\n",
      "\n",
      "Accuracy: 0.56\n",
      "Classification error: 0.43999999999999995\n",
      "Overall Precision: 0.5942275042444821\n",
      "Overall Recall: 0.5942275042444821\n",
      "Overall F1 Score: 0.5599999999999999\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sklearnstats([training_data,validation_data,testing_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset Results\n"
     ]
    }
   ],
   "source": [
    "print(\"Iris Dataset Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['class', 'a1', 'a2', 'a3','a4','a5','a6','id']\n",
    "dataset1 = pd.read_csv(\"../input_data/RobotDataset/Robot1\", names=colnames, header=None,delim_whitespace=True)\n",
    "dataset2 = pd.read_csv(\"../input_data/RobotDataset/Robot2\", names=colnames, header=None,delim_whitespace=True)\n",
    "frames = [dataset1,dataset2]\n",
    "dataset = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  a1  a2  a3  a4  a5  a6       id\n",
       "0      1   1   1   1   1   3   1   data_5\n",
       "1      1   1   1   1   1   3   2   data_6\n",
       "2      1   1   1   1   3   2   1  data_19\n",
       "3      1   1   1   1   3   3   2  data_22\n",
       "4      1   1   1   2   1   2   1  data_27"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Stats\n",
      "Recall of class 1 : 0.8795180722891566\n",
      "Precision of class 1 : 0.9358974358974359\n",
      "F1 Score of class 1 : 0.9068322981366458\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.921875\n",
      "Precision of class 0 : 0.855072463768116\n",
      "F1 Score of class 0 : 0.8872180451127819\n",
      "\n",
      "\n",
      "Accuracy: 0.8979591836734694\n",
      "Classification error: 0.10204081632653061\n",
      "Overall Precision: 0.8954849498327759\n",
      "Overall Recall: 0.9006965361445782\n",
      "Overall F1 Score: 0.8970251716247138\n"
     ]
    }
   ],
   "source": [
    "training_data,validation_data,testing_data = train_validate_test_split(dataset.drop('id',axis=1))\n",
    "classes = list(training_data['class'].unique())\n",
    "preds = knn_algorithm(training_data,training_data,classes,3,euclidean)\n",
    "cm = confusionmatrix(preds,list(training_data['class']),list(training_data['class'].unique()))\n",
    "print(\"Training Data Stats\")\n",
    "stats(cm,training_data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Stats\n",
      "Recall of class 1 : 0.6956521739130435\n",
      "Precision of class 1 : 0.64\n",
      "F1 Score of class 1 : 0.6666666666666666\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.6538461538461539\n",
      "Precision of class 0 : 0.7083333333333334\n",
      "F1 Score of class 0 : 0.68\n",
      "\n",
      "\n",
      "Accuracy: 0.673469387755102\n",
      "Classification error: 0.326530612244898\n",
      "Overall Precision: 0.6741666666666667\n",
      "Overall Recall: 0.6747491638795986\n",
      "Overall F1 Score: 0.6733333333333333\n"
     ]
    }
   ],
   "source": [
    "preds = knn_algorithm(training_data,validation_data,classes,3,euclidean)\n",
    "cm = confusionmatrix(preds,list(validation_data['class']),list(training_data['class'].unique()))\n",
    "print(\"Validation Data Stats\")\n",
    "stats(cm,training_data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Stats\n",
      "Recall of class 1 : 0.3939393939393939\n",
      "Precision of class 1 : 0.6842105263157895\n",
      "F1 Score of class 1 : 0.5\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.6470588235294118\n",
      "Precision of class 0 : 0.3548387096774194\n",
      "F1 Score of class 0 : 0.45833333333333337\n",
      "\n",
      "\n",
      "Accuracy: 0.48\n",
      "Classification error: 0.52\n",
      "Overall Precision: 0.5195246179966044\n",
      "Overall Recall: 0.5204991087344029\n",
      "Overall F1 Score: 0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "preds = knn_algorithm(training_data,testing_data,classes,3,euclidean)\n",
    "cm = confusionmatrix(preds,list(testing_data['class']),list(training_data['class'].unique()))\n",
    "print(\"Testing Data Stats\")\n",
    "stats(cm,training_data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn library results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on: training data\n",
      "Recall of class 1 : 0.8840579710144928\n",
      "Precision of class 1 : 0.9384615384615385\n",
      "F1 Score of class 1 : 0.9104477611940298\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.9487179487179487\n",
      "Precision of class 0 : 0.9024390243902439\n",
      "F1 Score of class 0 : 0.9249999999999999\n",
      "\n",
      "\n",
      "Accuracy: 0.9183673469387755\n",
      "Classification error: 0.08163265306122447\n",
      "Overall Precision: 0.9204502814258912\n",
      "Overall Recall: 0.9163879598662208\n",
      "Overall F1 Score: 0.9177238805970149\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accuracy on: validation data\n",
      "Recall of class 1 : 0.8333333333333334\n",
      "Precision of class 1 : 0.6896551724137931\n",
      "F1 Score of class 1 : 0.7547169811320755\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.64\n",
      "Precision of class 0 : 0.8\n",
      "F1 Score of class 0 : 0.7111111111111111\n",
      "\n",
      "\n",
      "Accuracy: 0.7346938775510204\n",
      "Classification error: 0.26530612244897955\n",
      "Overall Precision: 0.7448275862068966\n",
      "Overall Recall: 0.7366666666666667\n",
      "Overall F1 Score: 0.7329140461215933\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accuracy on: testing data\n",
      "Recall of class 1 : 0.45161290322580644\n",
      "Precision of class 1 : 0.7368421052631579\n",
      "F1 Score of class 1 : 0.5599999999999999\n",
      "\n",
      "\n",
      "Recall of class 0 : 0.7368421052631579\n",
      "Precision of class 0 : 0.45161290322580644\n",
      "F1 Score of class 0 : 0.5599999999999999\n",
      "\n",
      "\n",
      "Accuracy: 0.56\n",
      "Classification error: 0.43999999999999995\n",
      "Overall Precision: 0.5942275042444821\n",
      "Overall Recall: 0.5942275042444821\n",
      "Overall F1 Score: 0.5599999999999999\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sklearnstats([training_data,validation_data,testing_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here noth the dataset Robot and Iris perform lower than scikit learn library, but both the model performs \n",
    "# lower than 55% which means KNN is not suited for these datasets.\n",
    "# # Results can be imroved if the dataset is used with other methods. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
